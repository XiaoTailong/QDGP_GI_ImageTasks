{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "path = \"D:\\\\PycharmProjects\\\\SPI_QML\\\\untrain_QuGe\\\\deep-generative-prior\\\\data_zhai\\\\128\\\\128\\\\randomP\"\n",
    "images_patterns = os.listdir(path)\n",
    "images_patterns.sort()\n",
    "randomP = []\n",
    "for i, image in enumerate(images_patterns):\n",
    "    image_matrix = cv2.imread(path+\"\\\\\"+image, 0)\n",
    "    image_matrix = cv2.resize(image_matrix, (128, 128))\n",
    "    randomP.append(image_matrix)\n",
    "\n",
    "randomP = np.stack(randomP, axis=0)\n",
    "\n",
    "print(randomP.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 55  35  20 ... 106  93  75]\n",
      " [ 51  33  19 ... 100  88  70]\n",
      " [ 46  30  17 ...  91  80  64]\n",
      " ...\n",
      " [ 45  24  10 ... 104  89  68]\n",
      " [ 52  31  15 ... 109  94  74]\n",
      " [ 55  35  18 ... 109  95  76]]\n"
     ]
    }
   ],
   "source": [
    "print(randomP[0, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path+\"\\\\randomP.npy\", randomP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def test_code(orignal_image, patterns, data_array):\n",
    "    orignal_image = torch.Tensor(orignal_image)\n",
    "    # patterns = torch.Tensor(patterns, dtype=torch.float32)  # with shape (1024*3, 64, 64)\n",
    "    # I_orginal = torch.Tensor([torch.sum( orignal_image*patt ) for patt in patterns])\n",
    "    I_orginal = torch.sum(torch.sum(torch.multiply(patterns, orignal_image), dim=-1), dim=-1)\n",
    "    # I_orginal = torch.unsqueeze(I_orginal, dim=1)\n",
    "    print(I_orginal, flush=True)\n",
    "    print(torch.squeeze(data_array))\n",
    "    test_result = I_orginal - torch.squeeze(data_array) \n",
    "    return test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([557.6591, 491.0468, 553.6347,  ..., 594.7700, 627.2446, 656.6575])\n",
      "tensor([590.9124, 524.6450, 619.0330,  ..., 615.5419, 707.9060, 681.6646])\n",
      "tensor([-33.2533, -33.5983, -65.3983,  ..., -20.7719, -80.6614, -25.0071])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.1360)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wing_128 = cv2.imread(\"D:\\\\PycharmProjects\\\\SPI_QML\\\\untrain_QuGe\\\\deep-generative-prior\\\\data_zhai\\\\shot\\\\wing_128.png\",0)\n",
    "wing_128 = np.resize(wing_128/255.0, (128, 128))\n",
    "# wing_128 = wing_128/255.0\n",
    "\n",
    "patterns = np.load(path + \"\\\\randomp.npy\" )[:1024, :, :]/255.0\n",
    "\n",
    "data_array = np.load(\"D:\\\\PycharmProjects\\\\SPI_QML\\\\untrain_QuGe\\\\deep-generative-prior\\\\data_zhai\\\\128\\\\128\\\\buckets\\\\wing.npy\")\n",
    "data_array = data_array[:1024,]\n",
    "\n",
    "test_result = test_code(wing_128, torch.Tensor(patterns), torch.Tensor(data_array))\n",
    "\n",
    "print(test_result)\n",
    "A = torch.mean(torch.square(test_result))\n",
    "\n",
    "A/(128*128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DGI(signals, speckles):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    print(signals.shape)\n",
    "    s_avg = np.mean(signals)\n",
    "    r_avg = np.mean(speckles, 0)\n",
    "    r_avg_avg = np.mean(speckles)\n",
    "    N = len(signals) if len(signals) == len(speckles) else None\n",
    "    object = np.zeros_like(speckles[0])\n",
    "\n",
    "    for i in range(N):\n",
    "        object += (signals[i] - (s_avg / r_avg_avg) * np.mean(speckles[i])) * (speckles[i] - r_avg)\n",
    "    return object / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096,)\n",
      "[[-0.22820636 -0.25174393 -0.26616795 ... -0.13924943 -0.16790941\n",
      "  -0.19847432]\n",
      " [-0.23249046 -0.25262537 -0.26495795 ... -0.15488244 -0.18069539\n",
      "  -0.20701116]\n",
      " [-0.23293474 -0.24872666 -0.25844976 ... -0.16950129 -0.19093216\n",
      "  -0.21251   ]\n",
      " ...\n",
      " [-0.20078414 -0.22891372 -0.24830502 ... -0.10035811 -0.13152766\n",
      "  -0.16688011]\n",
      " [-0.21010673 -0.23847304 -0.25646487 ... -0.1088385  -0.14080611\n",
      "  -0.17664621]\n",
      " [-0.21995236 -0.24707377 -0.26317157 ... -0.12342391 -0.15373399\n",
      "  -0.18799329]]\n",
      "[[0.06405082 0.027006   0.00430461 ... 0.20405656 0.15894976 0.11084489]\n",
      " [0.05730825 0.02561873 0.00620897 ... 0.17945239 0.13882643 0.0974091 ]\n",
      " [0.05660902 0.03175475 0.01645196 ... 0.15644438 0.12271519 0.08875469]\n",
      " ...\n",
      " [0.10720955 0.06293755 0.03241836 ... 0.26526604 0.21620954 0.16056975]\n",
      " [0.09253711 0.04789252 0.01957589 ... 0.25191909 0.20160656 0.14519928]\n",
      " [0.07704147 0.03435618 0.00902049 ... 0.22896371 0.18125989 0.12734056]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = DGI(np.squeeze(data_array), patterns)\n",
    "# data_array (4096, 1)\n",
    "# pattern (4096, 128, 128)\n",
    "print(image)\n",
    "image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "print(image)\n",
    "cv2.imwrite(\"filename.png\", image*255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
